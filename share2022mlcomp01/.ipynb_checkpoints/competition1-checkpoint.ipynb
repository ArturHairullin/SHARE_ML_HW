{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66bedbf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 90) (50000,) (10000, 90)\n",
      "[-166.82478228   17.03360293  113.69477852           nan -182.21560391\n",
      "   -2.5217141  -199.9011239            nan  -45.70838808  468.27233559\n",
      "  -63.33463891 -121.35121091   45.20146719  121.33874894  -56.08040012\n",
      "   92.04755129  -49.72796237 -172.79995264  149.49489003    1.06973564\n",
      "   76.19716145   93.1497155   -26.61154998  149.62053047   25.51017328\n",
      "   -3.44698272  -12.729007     98.36387127   -9.76308572  841.50920559\n",
      "  -94.6785772  -264.04883457  -67.04916225 -191.92388278 -112.41415328\n",
      "   98.25448829   -2.50893744   -1.19170121  102.85690148   37.14970681\n",
      "  -76.50994561 -111.86074424 -109.19333799  191.81629577 -103.08943935\n",
      "  109.07747306  127.55247748 -325.18419348  141.43802559  -11.09520701\n",
      "    1.55266641  -92.02900693 -228.39060317 -181.94586975 -463.54744315\n",
      "   48.07108686  -60.37551777  -37.33845261   41.54185441   61.67857161\n",
      "  205.99933123  102.71881924  -14.79473026  -83.32990606  402.76220382\n",
      "  -45.61178758 -476.514226    -27.35019937 -142.86473381  -48.5915374\n",
      " -182.7099358    75.77204306   54.22540682  194.90877296  -33.66051489\n",
      "   65.53983925   27.51004777  116.10182745   66.32071592  -43.3596768\n",
      " -181.64640112 -332.45246632   85.08578848  -13.0246033    -9.56268136\n",
      "   83.76639169   85.73523197   56.78368279  -38.67563172  150.46255627]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Я попробовал использовать практически все алогритмы пройденные в курсе байес с нормальным распределением и бернулли,\n",
    "линейные методы перцептрон,логистическая регрессия,линейная регрессия,эластикнет,риджи\n",
    "/считал их через стохастический градиентный спуск/ и кнн, кнн дал мне лучший результат с параметрами \n",
    "которые я получил из дз про кнн и я решил остановиться на нем,\n",
    "на остальных методах я тоже немного крутил параметры,но результаты были хуже.\n",
    "Сначала я искал на 2000 выборки рандомом по \n",
    "{'n_neighbors': np.arange(1, 5000),'weights': ['distance','uniform'],'p':np.arange(1, 5000)}\n",
    "и получил в итоге 93%,потом я решил попробовать метрики из склерна [\"cityblock\", \"cosine\", \"euclidean\", \"l1\", \"l2\", \"manhattan\"]\n",
    "результат повысился до 94.9 и скорость поиска сильно повысилась я смог искать параметры по всей выборке за 20-30 минут,\n",
    "после многих запусков с изменением количества фолдов в кроссвалидации,я заметил,что параметр 'n_neighbors' всегда выбирался \n",
    "довольно малым меньше 50,поэтому я его снизил и получил прирост к точности до 95.9.\n",
    "Способы заполнения нанов я тоже использовал разные все стратегии simpleimputer mean, median, most frequent,но лучше оказался \n",
    "knnimputer прирост так или иначе не особо большой сотые или тысячные процента в зависимости от параметров модели.\n",
    "Индикатор заполнения я не вставлял,потому что он либо не давал прироста,либо ухудшал некоторые модели\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('train.csv')\n",
    "trainX = df.drop(['id','label'],axis=1).to_numpy()\n",
    "trainY = df['label'].to_numpy()\n",
    "testX = pd.read_csv('test.csv').drop(['id'],axis=1).to_numpy()\n",
    "print(trainX.shape, trainY.shape, testX.shape)\n",
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6801222d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import MissingIndicator, KNNImputer, SimpleImputer\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "imp = KNNImputer(n_neighbors=45, weights=\"distance\", add_indicator = False)\n",
    "#imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "trainX = imp.fit_transform(trainX)\n",
    "testX = imp.fit_transform(testX)\n",
    "indicator = MissingIndicator()\n",
    "train_mask_missing_values_only = indicator.fit_transform(trainX)\n",
    "test_mask_missing_values_only = indicator.fit_transform(testX)\n",
    "print(np.sum(train_mask_missing_values_only))\n",
    "print(np.sum(test_mask_missing_values_only))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de5c3b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 90) (50000,) (10000, 90)\n",
      "[-1.66824782e+02  1.70336029e+01  1.13694779e+02  2.55278933e-01\n",
      " -1.82215604e+02 -2.52171410e+00 -1.99901124e+02 -2.46492710e-01\n",
      " -4.57083881e+01  4.68272336e+02 -6.33346389e+01 -1.21351211e+02\n",
      "  4.52014672e+01  1.21338749e+02 -5.60804001e+01  9.20475513e+01\n",
      " -4.97279624e+01 -1.72799953e+02  1.49494890e+02  1.06973564e+00\n",
      "  7.61971614e+01  9.31497155e+01 -2.66115500e+01  1.49620530e+02\n",
      "  2.55101733e+01 -3.44698272e+00 -1.27290070e+01  9.83638713e+01\n",
      " -9.76308572e+00  8.41509206e+02 -9.46785772e+01 -2.64048835e+02\n",
      " -6.70491622e+01 -1.91923883e+02 -1.12414153e+02  9.82544883e+01\n",
      " -2.50893744e+00 -1.19170121e+00  1.02856901e+02  3.71497068e+01\n",
      " -7.65099456e+01 -1.11860744e+02 -1.09193338e+02  1.91816296e+02\n",
      " -1.03089439e+02  1.09077473e+02  1.27552477e+02 -3.25184193e+02\n",
      "  1.41438026e+02 -1.10952070e+01  1.55266641e+00 -9.20290069e+01\n",
      " -2.28390603e+02 -1.81945870e+02 -4.63547443e+02  4.80710869e+01\n",
      " -6.03755178e+01 -3.73384526e+01  4.15418544e+01  6.16785716e+01\n",
      "  2.05999331e+02  1.02718819e+02 -1.47947303e+01 -8.33299061e+01\n",
      "  4.02762204e+02 -4.56117876e+01 -4.76514226e+02 -2.73501994e+01\n",
      " -1.42864734e+02 -4.85915374e+01 -1.82709936e+02  7.57720431e+01\n",
      "  5.42254068e+01  1.94908773e+02 -3.36605149e+01  6.55398393e+01\n",
      "  2.75100478e+01  1.16101827e+02  6.63207159e+01 -4.33596768e+01\n",
      " -1.81646401e+02 -3.32452466e+02  8.50857885e+01 -1.30246033e+01\n",
      " -9.56268136e+00  8.37663917e+01  8.57352320e+01  5.67836828e+01\n",
      " -3.86756317e+01  1.50462556e+02]\n"
     ]
    }
   ],
   "source": [
    "print(trainX.shape, trainY.shape, testX.shape)\n",
    "print(trainX[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4956e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'weights': 'distance', 'n_neighbors': 21, 'metric': 'manhattan'}\n",
      "Validation score:  0.7624\n",
      "--- 285.2093291282654 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#поиск параметров для кнн\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import time\n",
    "start_time = time.time()\n",
    "param_grid = {'n_neighbors': np.arange(1, 50),'weights': ['distance','uniform'],'metric': [\"cityblock\", \\\n",
    "                                                                                        \"cosine\", \\\n",
    "                                                                                        \"euclidean\", \\\n",
    "                                                                                        \"l1\", \\\n",
    "                                                                                        \"l2\", \\\n",
    "                                                                                        \"manhattan\"]}\n",
    "svc = KNeighborsClassifier()\n",
    "clf = RandomizedSearchCV(svc, param_grid, n_iter=10, cv=100, random_state=1, refit=True)\n",
    "clf.fit(trainX[:50000], trainY[:50000])\n",
    "print('Best params: ', clf.best_params_)\n",
    "print('Validation score: ', clf.best_score_)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3a32c87e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#тест полученной модели через поиск\n",
    "score = clf.score(trainX[40000:50000], trainY[40000:50000]) \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc044a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "#обучение и тест итоговой модели\n",
    "cl = KNeighborsClassifier(n_neighbors = 29, metric = 'l2', weights = 'distance') \n",
    "#n_neighbors = 22, metric = 'euclidean', weights = 'uniform' параметры 94.9 модели\n",
    "cl.fit(trainX[:50000], trainY[:50000])\n",
    "score = cl.score(trainX[40000:50000], trainY[40000:50000]) \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96178930",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.821e-10, tolerance: 3.355e-15\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#остатки кода где я испытывал линейные методы \n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge,ElasticNet\n",
    "from scipy.stats import poisson,geom\n",
    "param_grid = {'alpha': np.arange(0.01,1,0.05),'positive':[True,False],'l1_ratio': np.arange(0.01,1,0.05),'max_iter':[100000],'tol':[1e-5,1e-10,1e-15,1e-20]}\n",
    "svc = ElasticNet()\n",
    "clf = RandomizedSearchCV(svc, param_grid, n_iter=10, cv=5, random_state=1, refit=True)\n",
    "clf.fit(trainX[:5000], trainY[:5000])\n",
    "print('Best params: ', clf.best_params_)\n",
    "print('Validation score: ', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f217bd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48446512687443777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.368e-09, tolerance: 3.342e-15\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "#остатки кода где я испытывал линейные методы \n",
    "from sklearn.linear_model import Ridge,ElasticNet\n",
    "cl = ElasticNet(tol = 1e-20, positive = False, max_iter = 100000, alpha=0.005101)\n",
    "cl.fit(trainX[:40000], trainY[:40000])\n",
    "score = cl.score(trainX[40000:50000], trainY[40000:50000]) \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cdbced7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8893\n"
     ]
    }
   ],
   "source": [
    "#остатки кода где я испытывал линейные методы через сгс\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "cl = SGDClassifier(loss=\"hinge\", shuffle=False, max_iter=100000, tol=1e-15, alpha=0.005101, penalty=\"l2\",\\\n",
    "                   learning_rate=\"adaptive\", eta0=0.000005)\n",
    "cl.fit(trainX[:50000], trainY[:50000])\n",
    "score = cl.score(trainX[40000:50000], trainY[40000:50000]) \n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "93590b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        id  label\n",
      "0        0      1\n",
      "1        1      8\n",
      "2        2      9\n",
      "3        3      9\n",
      "4        4      6\n",
      "...    ...    ...\n",
      "9995  9995      0\n",
      "9996  9996      8\n",
      "9997  9997      5\n",
      "9998  9998      3\n",
      "9999  9999      3\n",
      "\n",
      "[10000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "d = {'id': np.arange(0,10000), 'label': cl.predict(testX)}\n",
    "df = pd.DataFrame(data=d)\n",
    "print(df)\n",
    "df.to_csv('Khairullin_Artur.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0d8b2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ea8801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5064fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
